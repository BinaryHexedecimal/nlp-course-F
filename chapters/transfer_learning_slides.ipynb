{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Daniel Hershcovich"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Quiz results](https://absalon.instructure.com/courses/35895/quizzes/37714/statistics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-02T16:54:38.546624",
     "start_time": "2016-12-02T16:54:38.540051"
    },
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "- Natural Language Inference\n",
    "- Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Textual Entailment (RTE) = Natural Language Inference (NLI)\n",
    "\n",
    "Determining the logical relationship between two sentences.\n",
    "\n",
    "- Classification task\n",
    "- Requires commonsense and world knowledge\n",
    "- Requires general natural language understanding\n",
    "- Requires fine-grained reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- **A wedding party taking pictures**\n",
    "  - There is a funeral\t\t\t\t\t: **<span class=red>Contradiction</span>**\n",
    "  - They are outside\t\t\t\t\t: **<span class=blue>Neutral</span>**\n",
    "  - Someone got married\t\t\t\t    : **<span class=green>Entailment</span>**\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/31/Wedding_photographer_at_work.jpg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### State of the Art until 2015\n",
    "\n",
    "[<span class=blue>Lai and Hockenmaier, 2014, Jimenez et al., 2014, Zhao et al., 2014, Beltagy et al., 2015</span> etc.]\n",
    "\n",
    "- Engineered natural language processing pipelines\n",
    "- Various external resources\n",
    "- Specialized subcomponents\n",
    "- Extensive manual creation of **features**:\n",
    "  - Negation detection, word overlap, part-of-speech tags, dependency parses, alignment, unaligned matching, chunk alignment, synonym, hypernym, antonym, denotation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Networks for NLI\n",
    "\n",
    "As shown above, models for NLI heavily relied on engineered features. One reason why neural networks were not applied to this task is due to the absence of high-quality large-scale NLI corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Previous NLI corpora**:\n",
    "- Tiny data sets (1k-10k examples)\n",
    "- Partly synthetic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stanford Natural Inference Corpus (SNLI)**:\n",
    "- 500k sentence pairs\n",
    "- Two orders of magnitude larger than existing NLI data set\n",
    "- All examples generated by humans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent Sentence Encoding\n",
    "\n",
    "With the introduction of a large-scale NLI corpora, neural networks became feasible to train. A first baseline model by Bowman et al. (2015) used LSTMs to encode the premise and hypothesis independently of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<span class=blue>Bowman et al, 2015</span>]\n",
    "\n",
    "Same LSTM encodes premise and hypothesis\n",
    "\n",
    "<img src=\"dl-applications-figures/rte.svg\" width=800/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Last output vector as sentence representation\n",
    "\n",
    "Same LSTM encodes premise and hypothesis\n",
    "\n",
    "<img src=\"dl-applications-figures/rte_encoding.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> You can’t cram the meaning of a whole\n",
    "%&!\\$# sentence into a single \\$&!#* vector!\n",
    ">\n",
    "> -- <cite>Raymond J. Mooney</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Once both sentences are encoded as vectors, we can use a multi-layer perceptron followed by a softmax to model the probability of each class (entailment, neutral, contradiction) given the two sentences.\n",
    "\n",
    "<img src=\"dl-applications-figures/mlp.svg\" width=700/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Encoding\n",
    "\n",
    "The way we read the hypothesis could be influenced by our understanding of the premise.\n",
    "\n",
    "<img src=\"dl-applications-figures/conditional.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"dl-applications-figures/conditional_encoding.svg\" width=800/> "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Endcoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention [<span class=blue>Graves 2013</span>, <span class=blue>Bahdanau et al. 2015</span>]\n",
    "\n",
    "\n",
    "<img src=\"dl-applications-figures/attention.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Conditional encoding improves generalization compared to independent encoding of premise and hypothesis. Another improvement can be achieved by using a neural attention mechanism. To this end we compare the last output vector ($\\mathbf{h}_N$) with all premise output vectors (concatenated to $\\mathbf{Y}$) and model a probability distribution $\\alpha$ over premise output vectors using a softmax. Lastly, we obtain a context representation $\\mathbf{r}$ by weighting output vectors with the attention $\\alpha$, and use that context representation together with $\\mathbf{h}_N$ for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/attention_encoding.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img  src=\"./dl-applications-figures/camel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Contextual Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./dl-applications-figures/pink.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Encoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|\n",
    "| Attention | 100 | 3.9M | 242k | 85.4 | 83.2 | 82.3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Fuzzy Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./dl-applications-figures/mimes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word-by-word Attention [<span class=blue>Bahdanau et al. 2015</span>, <span class=blue>Hermann et al. 2015</span>, <span class=blue>Rush et al. 2015</span>]\n",
    "\n",
    "<img src=\"dl-applications-figures/word_attention.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "An extension to the attention mechanism described above is to allow the model to attend over premise output vectors for every word in the hypothesis. This can be achieved by a small adaption of the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/word_attention_encoding.svg\" width=800/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reordering\n",
    "\n",
    "<img src=\"./dl-applications-figures/reordering.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Garbage Can = Trashcan\n",
    "\n",
    "<img  src=\"./dl-applications-figures/trashcan.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Kids =  Girl + Boy\n",
    "\n",
    "<img  src=\"./dl-applications-figures/kids.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Snow is outside\n",
    "\n",
    "<img  src=\"./dl-applications-figures/snow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| Model | k | θ<sub>W+M</sub> | θ<sub>M</sub> | Train | Dev | Test |\n",
    "|-|-|-|-|-|-|-|\n",
    "| LSTM [<span class=blue>Bowman et al.</span>] | 100 | \\\\(\\approx\\\\)10M | 221k | 84.4 | - | 77.6|\n",
    "| Classifier [<span class=blue>Bowman et al.</span>]| - | - | - | 99.7 | - | 78.2|\n",
    "| Conditional Encoding | 159 | 3.9M | 252k | 84.4 | 83.0 | 81.4|\n",
    "| Attention | 100 | 3.9M | 242k | 85.4 | 83.2 | 82.3 |\n",
    "| Word-by-word Attention | 100 | 3.9M | 252k | 85.3 | **83.7** | **83.5** |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artefacts\n",
    "\n",
    "<img src=\"https://persagen.com/files/misc/arxiv1805.02266-table1.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-trained Representations\n",
    "\n",
    "Instead of training task-specific word representations, it is sometimes helpful to use pre-trained word vectors from word2vec or GloVe. Above, you can find a simply example of manually setting vectors of a word embedding matrix. Note that by setting `trainable=False`, the model cannot update these word embeddings during training. If we only want to use pre-trained word vectors as initializer so that we can fine-tune them based on our task, we would need set `trainable=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ELMo\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/7/74/Elmo_from_Sesame_Street.gif\"/>\n",
    "<img src=\"https://raw.githubusercontent.com/dsindex/blog/master/images/ngram_cnn_highway_1.png\"/>\n",
    "<img src=\"http://jalammar.github.io/images/elmo-forward-backward-language-model-embedding.png\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/300/0*2XpE-VjhhLGkFDYg.jpg\"/>\n",
    "<img src=\"http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png\"/>\n",
    "<img src=\"http://jalammar.github.io/images/bert-next-sentence-prediction.png\"/>\n",
    "<img src=\"http://jalammar.github.io/images/bert-tasks.png\"/>\n",
    "<img src=\"https://storage.googleapis.com/groundai-web-prod/media/users/user_234892/project_363715/images/supplemental/bylayer_base.png\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GLUE\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1200/0*-k_fjBnCuByNye4v\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Projecting Representations\n",
    "\n",
    "Sometimes we want to work with pre-trained word vectors (e.g. $300$ dimensional word2vec vectors), but use a different hidden size for our RNN. We can learn a linear projection from one vector space to another via `tf.contrib.layers.linear`. If we want to use a non-linear projection, we can simply call a non-linear function like `tanh` on the output of `linear`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- [The State of Transfer Learning in NLP](http://ruder.io/state-of-transfer-learning-in-nlp/)\n",
    "- [An Overview of Multi-Task Learning in Deep Neural Networks](https://arxiv.org/pdf/1706.05098.pdf)\n",
    "- [Linguistic Knowledge and Transferability of Contextual Representations](https://www.aclweb.org/anthology/N19-1112.pdf)\n",
    "- [GLUE: a multi-task benchmark and analysis platform for natural language understanding](https://openreview.net/pdf?id=rJ4km2R5t7)\n",
    "- [SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems](https://w4ngatang.github.io/static/papers/superglue.pdf)\n",
    "- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](http://jalammar.github.io/illustrated-bert/)\n",
    "- [Character-Aware Neural Language Models](https://arxiv.org/pdf/1508.06615.pdf)\n",
    "- [Annotation Artifacts in Natural Language Inference Data](https://www.aclweb.org/anthology/N18-2017.pdf)\n",
    "- [Breaking NLI Systems with Sentences that Require Simple Lexical Inferences](https://www.aclweb.org/anthology/P18-2103.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}