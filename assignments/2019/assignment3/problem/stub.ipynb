{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Cross-lingual Dependency Parsing\n",
    "\n",
    "In this assignment you will build a cross-lingual transition-based dependency parser. You will have access to English data for training, but your goal with be to optimize the performance of your model on Danish data.\n",
    "\n",
    "Your mark will depend on:\n",
    "\n",
    "* The **reasoning** you provide to explain your dependency parsing model and its predictions,\n",
    "* The correct **implementation** of your dependency parsing model, and\n",
    "* The **performance** of your model on a held-out test set.\n",
    "\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The data in `data/ud/`. Remember to un-tar the `data.tar.gz` file. The folder contains the train set, the dev set and **a pseudo test set, which matches exactly the name and format of the actual held-out test set**. Note that this pseudo test set is just a copy of the development data, but during grading unseen test data will be used instead.\n",
    "\n",
    "* Libraries on the [docker image](https://cloud.docker.com/repository/docker/bjerva/stat-nlp-book) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn, torch 1.2.0 and tensorflow 1.14.0. \n",
    "\n",
    "\n",
    "As with the previous assignment, since we have to run the notebooks of all students, and because writing efficient code is important, your notebook should run in 10 minutes at most, including package loading time, on your machine.\n",
    "Furthermore, you are welcome to provide a saved version of your model with loading code. In this case loading, testing, and evaluation has to be done in 10 minutes. You can use the pseudo test set to check if this is the case, and assume that it will be fine for the held-out test set if so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2019/assignment3/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCPH ID (of the form `xxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to assess your solution. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit these**. \n",
    "2. **Assessment** Sections: these sections are used for evaluating the output of your code. **Do not edit these**. \n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "**Do not share** this assignment publicly, by uploading it online, emailing it to friends etc. \n",
    "\n",
    "**Do not** copy code from the Web or from other students, this will count as plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook\n",
    "and possibly in saved model files. \n",
    "* **Rename this notebook to your UCPH ID** (of the form \"xxxxxx\"), if you have not already done so.\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to Absalon, zipped with any saved model files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#! SETUP 1\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "from os.path import join\n",
    "from collections import deque\n",
    "import copy\n",
    "from statnlpbook.dep import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In this assignment, we will use [Universal Dependencies](https://universaldependencies.org)\n",
    "treebanks in English and Danish, which can be found in the `/data/ud/`\n",
    "directory of the repository.\n",
    "The treebanks are given in [the CoNLL-U format](https://universaldependencies.org/format.html).\n",
    "Familiarize yourself with the format and the information contained in it.\n",
    "\n",
    "For example, this is a simplified version of one of the annotated sentences from the (English) training set:\n",
    "~~~\n",
    "# sent_id = email-enronsent30_01-0030\n",
    "# text = I would like to get this done ASAP.\n",
    "1 \tI     \tI     \tPRON  \tPRP \t_ \t3 \tnsubj  \t_ \t_             \n",
    "2 \twould \twould \tAUX   \tMD  \t_ \t3 \taux    \t_ \t_             \n",
    "3 \tlike  \tlike  \tVERB  \tVB  \t_ \t0 \troot   \t_ \t_             \n",
    "4 \tto    \tto    \tPART  \tTO  \t_ \t5 \tmark   \t_ \t_             \n",
    "5 \tget   \tget   \tVERB  \tVB  \t_ \t3 \txcomp  \t_ \t_             \n",
    "6 \tthis  \tthis  \tPRON  \tDT  \t_ \t5 \tobj    \t_ \t_             \n",
    "7 \tdone  \tdo    \tVERB  \tVBN \t_ \t5 \txcomp  \t_ \t_             \n",
    "8 \tASAP  \tasap  \tADV   \tRB  \t_ \t7 \tadvmod \t_ \t_ \n",
    "9 \t.     \t.     \tPUNCT \t.   \t_ \t3 \tpunct  \t_ \t_                                                    \n",
    "~~~\n",
    "\n",
    "In this assignment, we will use the `ID`, `FORM`, `LEMMA`, `UPOS`,\n",
    "`XPOS`, `HEAD` and `DEPREL` columns,\n",
    "and ignore the `FEATS`, `DEPS` and `MISC` columns (the 6th, 9th and 10th).\n",
    "\n",
    "We will use the `load_conllu` and `save_to_conllu` functions from the\n",
    "`dep` module in the `statnlpbook` package (imported above) to load CoNLL-U files to\n",
    "sequences of `dict`s and to save them back.\n",
    "You will use these functions for training and evaluating a dependency parsing model,\n",
    "and for saving your model's predictions in this format.\n",
    "\n",
    "Run the following cell to load the English training data and\n",
    "the Danish development data,\n",
    "and to show an example Python representation\n",
    "for an English training sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed loading line 0 in '':\n../../../../data/ud/en_ewt-ud-train.conllu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/work/statnlpbook/dep.py\u001b[0m in \u001b[0;36mload_conllu_lines\u001b[0;34m(f, file_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"form\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lemma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"xpos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"head\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"deprel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Skip special nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 10, got 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-26ab0d082946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_book_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ud\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en_ewt-ud-train.conllu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_conllu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdev_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_book_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ud\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"da_ddt-ud-dev.conllu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_conllu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1740\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/statnlpbook/dep.py\u001b[0m in \u001b[0;36mload_conllu\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_conllu_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_conllu_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/statnlpbook/dep.py\u001b[0m in \u001b[0;36mload_conllu_lines\u001b[0;34m(f, file_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed loading line %d in '%s':\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed loading line 0 in '':\n../../../../data/ud/en_ewt-ud-train.conllu"
     ]
    }
   ],
   "source": [
    "train_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"en_ewt-ud-train.conllu\")\n",
    "train_data = load_conllu(train_file_path)\n",
    "dev_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"da_ddt-ud-dev.conllu\")\n",
    "dev_data = load_conllu(dev_file_path)\n",
    "train_data[1740]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['da_ddt-ud-dev.conllu',\n",
       " 'da_ddt-ud-test.conllu',\n",
       " 'en_ewt-ud-train.conllu',\n",
       " 'data.tar.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(join(_snlp_book_dir, \"data\", \"ud\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Develop an oracle for training the parser\n",
    "\n",
    "In this task, you will implement a static oracle for the arc-standard transition system.\n",
    "The oracle's job is to get a parsed dependency tree, and return the sequence\n",
    "of transitions (actions) needed to reach the tree in the arc-standard transition system.\n",
    "\n",
    "You can find a description of the expected behaviour of the oracle in the\n",
    "[reading material](https://web.stanford.edu/~jurafsky/slp3/14.pdf)\n",
    "and in the [dependency parsing lecture slides](https://nbviewer.jupyter.org/github/copenlu/stat-nlp-book/blob/master/chapters/dependency_parsing_slides.ipynb).\n",
    "\n",
    "To perform this task, edit the `TODO` block in the following.\n",
    "You may also edit anything else in this cell as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## You should improve this cell\n",
    "\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self, nodes):\n",
    "        # This implements the initial configuration for a sentence\n",
    "        self.arcs = set()\n",
    "        self.nodes = nodes\n",
    "        self.buffer = deque(nodes[1:])  # Initialize with the words\n",
    "        self.stack = [nodes[0]]  # Initialize with the root\n",
    "\n",
    "    def apply_transition(self, transition):\n",
    "        \"\"\"Modify the configuration accordingly, preparing for the next step\"\"\"\n",
    "        if transition == \"shift\":\n",
    "            token = self.buffer.popleft()\n",
    "            self.stack.append(token)\n",
    "        elif transition.startswith(\"leftArc\"):\n",
    "            head = self.stack[-1]\n",
    "            dependent = self.stack.pop(-2)\n",
    "            label = transition.split(\"-\")[1]\n",
    "            self.arcs.add((int(head[\"index\"]), int(dependent[\"index\"]), label))\n",
    "        elif transition.startswith(\"rightArc\"):\n",
    "            head = self.stack[-2]\n",
    "            dependent = self.stack.pop()\n",
    "            label = transition.split(\"-\")[1]\n",
    "            self.arcs.add((int(head[\"index\"]), int(dependent[\"index\"]), label))\n",
    "\n",
    "def oracle(tree):\n",
    "    \"\"\"Given a parsed (gold-standard) sentence, return its arc-standard oracle transition sequence.\n",
    "    Args:\n",
    "        tree: A parsed sentence.\n",
    "    Returns:\n",
    "        Sequence of transitions, as strings: \"shift\" / \"leftArc-\"+LABEL / \"rightArc-\"+LABEL.\n",
    "    \"\"\"\n",
    "    transitions = []  # This stores the generated transition strings\n",
    "    configuration = Configuration(tree[\"nodes\"])  # Initialize the configuration\n",
    "    # While the buffer is not empty or the stack contains non-root nodes:\n",
    "    while configuration.buffer or len(configuration.stack) > 1:\n",
    "        ### TODO: replace with code to find the correct next transition:\n",
    "        transition = None\n",
    "        break\n",
    "        ### END TODO\n",
    "        transitions.append(transition)\n",
    "        configuration.apply_transition(transition)\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Correctness of the oracle implementation (20 pts)\n",
    "\n",
    "We assess if your code implements a correct oracle for the arc-standard transition system:\n",
    "\n",
    "* 0-5 pts: the oracle does not run correctly or does not constitute a correct oracle\n",
    "* 5-15 pts: the oracle runs, but is missing some of the requirements laid out above\n",
    "* 15-20 pts: the oracle correctly implements the requirements\n",
    "\n",
    "You can test your oracle by running it on some sentences from the training set (will not be assessed explicitly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle(train_data[1740])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Design your cross-lingual parser\n",
    "\n",
    "Before implementing your parser, make the necessary design choices\n",
    "and motivate them. Note that there are many correct parser designs,\n",
    "but you must provide reasonable explanations for your choices.\n",
    "\n",
    "Specifically, answer the following questions:\n",
    "\n",
    "2.1. What challenges are there in our setting, where training is done on one language (English) and parsing on a different language (Danish)?\n",
    "\n",
    "2.2. Out of the CoNLL-U columns (`ID`, `FORM`, `LEMMA`, `UPOS`, `XPOS`, `HEAD` and `DEPREL`), which are you going to use for features for the parser? Justify your decision.\n",
    "\n",
    "2.3. Can beam search be used to improve the parser? How? What kind of parsing errors may it help to overcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess your explanation (30 pts)\n",
    "\n",
    "We will mark the explanation along the following dimension: \n",
    "\n",
    "* Substance (30pts): correctly explained reasons for model design challenges and decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## <font color='blue'>Task 3</font>: Develop and train a dependency parser\n",
    "\n",
    "In this task, you will develop a dependency parser,\n",
    "train it on English, and apply it to Danish.\n",
    "\n",
    "**Your task is to build a dependency parser, train it on `en_ewt-ud-train.conllu`\n",
    "(using `da_ddt-ud-dev.conllu` for tuning and model selection if you like),\n",
    "and save its output on `da_ddt-ud-test.conllu` in CoNLL-U format.**\n",
    "\n",
    "This model should, at a minimum, implement the following:\n",
    "\n",
    "1. Classifier to select the next transition given a configuration.\n",
    "\n",
    "1. Produce valid dependency trees for input sentences from `da_ddt-ud-test.conllu`\n",
    "and from an unseen test set.\n",
    "\n",
    "You may assume gold features, i.e.,\n",
    "that the `ID`, `FORM`, `LEMMA`, `UPOS`, and `XPOS` fields in the input\n",
    "sentences are annotated correctly\n",
    "(note that even though it simplifies things, this is an unrealistic scenario,\n",
    "since for real text no gold part-of-speech tags are available, for example, and the\n",
    "parser would have to use automatically tagged text).\n",
    "Of course, the `HEAD` and `DEPREL` fields will be given only during training.\n",
    "\n",
    "You are allowed to use PyTorch or Tensorflow,\n",
    "and static or contextual word representations,\n",
    "as in previous assignments.\n",
    "You are also free to add other improvements, such as\n",
    "cross-lingual word embeddings\n",
    "(e.g., [fastText](https://fasttext.cc/docs/en/aligned-vectors.html)),\n",
    "recurrent neural networks for input representations,\n",
    "attention over elements in the configuration,\n",
    "or beam search for decoding.\n",
    "Please keep the running time limit in mind,\n",
    "if you choose to add this type of extension.\n",
    "\n",
    "Your task then consists of three steps:\n",
    "\n",
    "1. Write code that builds a dependency parser that fulfills the requirements laid out above.\n",
    "\n",
    "2. Train your model on `en_ewt-ud-train.conllu`, optionally using `da_ddt-ud-dev.conllu` as a development set.\n",
    "If you perform hyperparameter search, model selection or early stopping, make sure the runtime requirement is not\n",
    "violated. Otherwise run the tuning yourself and include the best hyperparameters in the code.\n",
    "\n",
    "3. Run your model on `da_ddt-ud-test.conllu` and save the\n",
    "result as a separate `.conllu` file. Reminder: the test data you have is just a copy of the development data,\n",
    "but during grading an unseen test file will be used instead.\n",
    "\n",
    "If training your model takes more than 10 minutes,\n",
    "you must also implement the saving and loading functions for your model,\n",
    "and provide saved model files along with your submitted notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `evaluate_las` will be used to score your model's predictions.\n",
    "\n",
    "As a basic test, loading the CoNLL-U files and immediately saving them back should produce well-formed `.conllu` files\n",
    "that score 100% LAS against the original ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_copy_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"da_ddt-ud-dev_copy.conllu\")\n",
    "save_to_conllu(dev_data, dev_copy_file_path)\n",
    "evaluate_las(dev_file_path, dev_copy_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the following cell to implement your model.\n",
    "You should not have to modify `build_tree`, and in `parse` you should\n",
    "only have to edit the `TODO` block. However, you are free to edit any\n",
    "part of the cell as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## You should improve this cell\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Instantiate a dependency parser model.\n",
    "    Returns:\n",
    "        A dependency parser model.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def train_model(model, train_data, dev_data):\n",
    "    \"\"\"Train a dependency parser model on the given sequence of parsed sentences.\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_data: The sequence of parsed sentences to train on.\n",
    "        dev_data: The sequence of parsed sentences to (optionally) use for development.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    \"\"\"Save a dependency parser model to the given file path.\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        file_path: file path to save the model to.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def load_model(file_path):\n",
    "    \"\"\"Load a dependency parser model from a given file path.\n",
    "    Args:\n",
    "        file_path: file path to load the model from.\n",
    "    Returns:\n",
    "        A dependency parser model.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def build_tree(sentence, configuration):\n",
    "    \"\"\"Insert the arcs from a configuration to a tree\"\"\"\n",
    "    tree = copy.deepcopy(sentence)\n",
    "    for arc in configuration.arcs:\n",
    "        head_index, dependent_index, label = arc\n",
    "        dependent = tree[\"nodes\"][dependent_index]\n",
    "        dependent[\"head\"] = str(head_index)\n",
    "        dependent[\"deprel\"] = label\n",
    "    return tree\n",
    "\n",
    "def parse(model, data):\n",
    "    \"\"\"Apply a dependency parser model to parse the given sequence of (test) sentences.\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        data: The sequence of unparsed sentences to parse,\n",
    "        in the same format as parsed sentences but without the\n",
    "        \"head\" and \"deprel\" fields.\n",
    "    Returns:\n",
    "        The sequence of sentences parsed by the model.\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    for sentence in data:\n",
    "        configuration = Configuration(sentence[\"nodes\"])  # Initialize the configuration\n",
    "        # While the buffer is not empty or the stack contains non-root nodes:\n",
    "        while configuration.buffer or len(configuration.stack) > 1:\n",
    "            ### TODO: replace with code to find the predicted next transition:\n",
    "            transition = None\n",
    "            break\n",
    "            ### END TODO\n",
    "            configuration.apply_transition(transition)\n",
    "        trees.append(build_tree(sentence, configuration))\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Correctness of the implementation (30 pts)\n",
    "\n",
    "We assess if your code implements a correct dependency parser (20 points):\n",
    "\n",
    "* 0-5 pts: the model does not run correctly or does not constitute a dependency parser\n",
    "* 5-15 pts: the model runs, but is missing some of the requirements laid out above\n",
    "* 15-20 pts: the model correctly implements the requirements\n",
    "\n",
    "Additionally, we will assess how well your model performs on an unseen test set (10 points):\n",
    "\n",
    "* 0-5 pts: performance worse than a simple baseline model\n",
    "* 5-10 pts: performance better than a simple baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "train_model(model, train_data, dev_data)\n",
    "# Evaluate on the development set to check yourself:\n",
    "dev_data_pred = parse(model, dev_data)\n",
    "dev_pred_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"dev_predictions.conllu\")\n",
    "save_to_conllu(dev_data_pred, dev_pred_file_path)\n",
    "evaluate_las(dev_file_path, dev_pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Do not modify this cell. We will run this on an unseen test set:\n",
    "test_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"da_ddt-ud-test.conllu\")\n",
    "test_data = load_conllu(test_file_path)\n",
    "test_data_pred = parse(model, test_data)\n",
    "test_pred_file_path = join(_snlp_book_dir, \"data\", \"ud\", \"test_predictions.conllu\")\n",
    "save_to_conllu(test_data_pred, test_pred_file_path)\n",
    "evaluate_las(test_file_path, test_pred_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 4</font>: Error analysis\n",
    "\n",
    "Reflect on the model implemented in Task 3.\n",
    "What worked and didn't work well, and how would you explain this?\n",
    "You are welcome to perform a small error analysis on the development set\n",
    "in order to answer the last question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 4</font>: Assess your explanation (20 pts)\n",
    "\n",
    "We will mark the explanation along the following dimension: \n",
    "\n",
    "* Substance (20pts): correctly explained reasons for performance of the model."
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
