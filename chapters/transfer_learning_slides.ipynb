{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "<style>\n",
    ".rendered_html td {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    ".rendered_html th {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%load_ext tikzmagic"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Natural language inference\n",
    "- Multi-task learning\n",
    "- Pre-trained encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Textual Entailment = Natural Language Inference\n",
    "\n",
    "Determining the logical relationship between two sentences.\n",
    "\n",
    "- Classification task\n",
    "- Requires commonsense and world knowledge\n",
    "- Requires general natural language understanding\n",
    "- Requires fine-grained reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recognizing Textual Entailment (RTE)\n",
    "\n",
    "[Dagan et al., 2005](http://u.cs.biu.ac.il/~dagan/publications/RTEChallenge.pdf)\n",
    "\n",
    "- Text (premise) T\n",
    "- Hypothesis H\n",
    "\n",
    "T entails H if, typically, a human reading T would infer that H is most likely true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Positive:\n",
    "\n",
    "> “Google files for its long awaited IPO.”\n",
    "\n",
    "<center>\n",
    "$\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “Google goes public.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Negative:\n",
    "\n",
    "> “Regan attended a ceremony in Washington to commemorate the landings in Normandy.”\n",
    "\n",
    "<center>\n",
    "$\\not\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “Washington is located in Normandy.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stanford Natural Language Inference (SNLI) corpus\n",
    "\n",
    "[Bowman et al., 2015](https://nlp.stanford.edu/pubs/snli_paper.pdf): crowdsourced NLI using image captions.\n",
    "\n",
    "570K sentence pairs, two orders of magnitude larger than other NLI resources (1K-10K examples).\n",
    "\n",
    " **A wedding party taking pictures**\n",
    "- There is a funeral\t\t\t\t\t: **<span class=red>Contradiction</span>**\n",
    "- They are outside\t\t\t\t\t    : **<span class=blue>Neutral</span>**\n",
    "- Someone got married\t\t\t\t    : **<span class=green>Entailment</span>**\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/31/Wedding_photographer_at_work.jpg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-NLI (MNLI)\n",
    "\n",
    "[Williams et al., 2018](https://www.nyu.edu/projects/bowman/multinli/paper.pdf): more diverse domains.\n",
    "\n",
    "Entailment:\n",
    "\n",
    "> “The legislation was widely hailed as a model for the country.”\n",
    "\n",
    "<center>\n",
    "$\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “Many people thought the legislation was a model for the country.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Neutral:\n",
    "\n",
    "> “The program has helped victims in 90 court cases, and 150 legal counseling sessions have been held there.”\n",
    "\n",
    "<center>\n",
    "?\n",
    "</center>\n",
    "\n",
    "> “Victims from 90 grand jury court cases were helped by the program.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Contradiction:\n",
    "\n",
    "> “As a result, Chris Schneider, executive director of Central California Legal Services, is building a lawsuit against Alpaugh Irrigation.”\n",
    "\n",
    "<center>\n",
    "$\\Rightarrow\\neg$\n",
    "</center>\n",
    "\n",
    "> “Central California Legal Services’ executive director decided not to pursue a lawsuit against Alpaugh Irrigation.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GLUE benchmark\n",
    "\n",
    "[Wang et al., 2019](https://openreview.net/pdf?id=rJ4km2R5t7): collection of sentence- and sentence-pair-classification tasks.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/6aa371f872f49eb69a6ad185c74194d95c01257f/6-Table2-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GLUE: Winograd NLI (WNLI)\n",
    "\n",
    "World knowledge and logical reasoning, presented as NLI.\n",
    "\n",
    "Positive:\n",
    "\n",
    "> “I put the cake away in the refrigerator. It has a lot of butter in it.”\n",
    "\n",
    "<center>\n",
    "$\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “The cake has a lot of butter in it.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Negative:\n",
    "\n",
    "> “The large ball crashed right through the table because it was made of styrofoam.”\n",
    "\n",
    "<center>\n",
    "$\\not\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “The large ball was made of styrofoam.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GLUE benchmark\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/d9f6ada77448664b71128bb19df15765336974a6/2-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SuperGLUE\n",
    "\n",
    "[Wang et al., 2019](https://arxiv.org/pdf/1905.00537v2.pdf): harder NLI, for a meaningful comparison.\n",
    "\n",
    "> “Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.”\n",
    "\n",
    "<center>\n",
    "$\\not\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “Christopher Reeve had an accident.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RTE/NLI state of the art until 2015\n",
    "\n",
    "[Lai and Hockenmaier, 2014](https://www.aclweb.org/anthology/S14-2055.pdf),\n",
    "[Jimenez et al., 2014](https://www.aclweb.org/anthology/S14-2131.pdf),\n",
    "[Zhao et al., 2014](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6889713),\n",
    "[Beltagy et al., 2016](https://www.aclweb.org/anthology/J16-4007.pdf) and others:\n",
    "engineered pipelines.\n",
    "\n",
    "- Various external resources\n",
    "- Specialized subcomponents\n",
    "- Extensive use of **features**:\n",
    "  - Negation detection, word overlap, part-of-speech tags, dependency parses, alignment, symbolic meaning representation\n",
    "  \n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/fca1e631b8f93036065311eb92727c509423475a/9-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural networks for NLI\n",
    "\n",
    "Large-scale NLI corpora: NNs are feasible to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independent sentence encoding\n",
    "\n",
    "[Bowman et al, 2015](https://www.aclweb.org/anthology/D15-1075.pdf): same LSTM encodes premise and hypothesis.\n",
    "\n",
    "<img src=\"dl-applications-figures/rte.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last output vector as sentence representation.\n",
    "\n",
    "<img src=\"dl-applications-figures/rte_encoding.svg\" width=1500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MLP to classify as entailment/neutral/contradiction.\n",
    "\n",
    "<img src=\"dl-applications-figures/mlp.svg\" width=1400/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional encoding\n",
    "\n",
    "The way we read the hypothesis could be influenced by our understanding of the premise.\n",
    "\n",
    "<img src=\"dl-applications-figures/conditional.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/conditional_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional endcoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> You can’t cram the meaning of a whole\n",
    "%&!\\$# sentence into a single \\$&!#* vector!\n",
    ">\n",
    "> -- <cite>Raymond J. Mooney</cite>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention\n",
    "\n",
    "<img src=\"dl-applications-figures/attention.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/attention_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img  src=\"./dl-applications-figures/camel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Contextual understanding\n",
    "\n",
    "<img src=\"./dl-applications-figures/pink.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional encoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Attention</td>\n",
    "<td>82.3</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Fuzzy attention\n",
    "\n",
    "<img  src=\"./dl-applications-figures/mimes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word-by-word attention\n",
    "\n",
    "<img src=\"dl-applications-figures/word_attention.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/word_attention_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Reordering\n",
    "\n",
    "<img src=\"./dl-applications-figures/reordering.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Synonyms\n",
    "\n",
    "<img  src=\"./dl-applications-figures/trashcan.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Hypernyms\n",
    "\n",
    "<img src=\"./dl-applications-figures/kids.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lexical inference\n",
    "\n",
    "<img src=\"./dl-applications-figures/snow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional encoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Attention</td>\n",
    "<td>82.3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Word-by-word attention</td>\n",
    "<td><strong>83.5</strong></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Composition\n",
    "\n",
    "[Bowman et al., 2016](https://www.aclweb.org/anthology/P16-1139.pdf):\n",
    "compositional vector representation based on syntactic structure.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/36c097a225a95735271960e2b63a2cb9e98bff83/1-Figure1-1.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLI artefacts\n",
    "\n",
    "SNLI and MNLI are **crowdsourced**.\n",
    "\n",
    "[Gururangan et al., 2018](https://www.aclweb.org/anthology/N18-2017.pdf): hypothesis phrasing alone gives out the class.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/2997b26ffb8c291ce478bd8a6e47979d5a55c466/2-Table1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lexical entailment\n",
    "\n",
    "[Glockner et al., 2018](https://www.aclweb.org/anthology/P18-2103.pdf): very **simple** examples that are hard for models.\n",
    "\n",
    "<img src=\"https://persagen.com/files/misc/arxiv1805.02266-table1.png\" width=80%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer learning\n",
    "\n",
    "Reading material:\n",
    "\n",
    "- [The State of Transfer Learning in NLP](http://ruder.io/state-of-transfer-learning-in-nlp/)\n",
    "- [An Overview of Multi-Task Learning in Deep Neural Networks](https://arxiv.org/pdf/1706.05098.pdf)\n",
    "\n",
    "[Quiz results](https://absalon.instructure.com/courses/35895/quizzes/37714/statistics)\n",
    "\n",
    "<img src=\"https://ruder.io/content/images/2019/08/transfer_learning_taxonomy.png\" width=45%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A very brief history of transfer learning in NLP\n",
    "\n",
    "- [Collobert et al., 2011](https://arxiv.org/pdf/1103.0398.pdf): many tasks with shared embeddings.\n",
    "- [word2vec](https://arxiv.org/pdf/1301.3781.pdf), [GloVe](https://www.aclweb.org/anthology/D14-1162.pdf) and others:\n",
    "pre-trained word embeddings.\n",
    "- [ELMo](https://www.aclweb.org/anthology/N18-1202.pdf), [BERT](https://www.aclweb.org/anthology/N19-1423.pdf) and others:\n",
    "pre-trained contextualized embeddings.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/2538e3eb24d26f31482c479d95d2e26c0e79b990/3-Figure1-1.png\" width=30%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-task learning in NLP\n",
    "\n",
    "- [Caruana, 1997](https://www.cs.cornell.edu/~caruana/mlj97.pdf): introduction of MTL.\n",
    "- [Hashimoto et al, 2017](https://www.aclweb.org/anthology/D17-1206.pdf),\n",
    "[Bjerva, 2017](https://www.aclweb.org/anthology/W17-0225.pdf),\n",
    "[Bollmann et al., 2018](https://www.aclweb.org/anthology/W18-3403.pdf),\n",
    "[Hershcovich et al., 2018](https://www.aclweb.org/anthology/P18-1035.pdf),\n",
    "[Augenstein et al., 2018](https://www.aclweb.org/anthology/N18-1172.pdf) and many others: MTL for NLP.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/ade0c116120b54b57a91da51235108b75c28375a/1-Figure1-1.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLI and parsing\n",
    "\n",
    "[Bowman et al., 2016](https://www.aclweb.org/anthology/P16-1139.pdf):\n",
    "transition-based parsing and NLI. Stack-augmented Parser-Interpreter Neural Network (SPINN).\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/36c097a225a95735271960e2b63a2cb9e98bff83/2-Figure2-1.png\" width=150%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-task\n",
    "\n",
    "[Augenstein et al., 2018](https://www.aclweb.org/anthology/N18-1172.pdf):\n",
    "sentiment analysis, stance detection, fake news detection and NLI\n",
    "with a Label Embedding Layer.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/64c5f7055b2e6982b6b95e069b22230d13a134bb/4-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-trained embeddings\n",
    "\n",
    "General-purpose representations trained on large datasets (usually unsupervised):\n",
    "\n",
    "- [word2vec](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "- [GloVe](https://www.aclweb.org/anthology/D14-1162.pdf)\n",
    "- [ELMo](https://www.aclweb.org/anthology/N18-1202.pdf)\n",
    "- [BERT](https://www.aclweb.org/anthology/N19-1423.pdf)\n",
    "\n",
    "are all forms of transfer learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GLUE\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/d9f6ada77448664b71128bb19df15765336974a6/2-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## T5\n",
    "\n",
    "[Raffel et al., 2019](https://arxiv.org/pdf/1910.10683.pdf): train on ALL the tasks!\n",
    "\n",
    "<img src=\"dl-applications-figures/t5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## T5\n",
    "\n",
    "Currently [best on GLUE](https://gluebenchmark.com/leaderboard)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further reading\n",
    "\n",
    "- [Ruder, 2019. The State of Transfer Learning in NLP](https://ruder.io/state-of-transfer-learning-in-nlp/)\n",
    "- [Liu et al., 2019. Linguistic Knowledge and Transferability of Contextual Representations](https://www.aclweb.org/anthology/N19-1112.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}