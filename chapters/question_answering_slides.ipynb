{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "<style>\n",
    ".rendered_html td {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    ".rendered_html th {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    "</style>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../statnlpbook/\")\n",
    "\n",
    "#util.execute_notebook('relation_extraction.ipynb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\a}{\\alpha}\n",
    "\\newcommand{\\b}{\\beta}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question Answering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Schedule\n",
    "\n",
    "* Relation extraction via reading comprehension (15 min.)\n",
    "* Question answering (10 min.)\n",
    "* Machine reading comprehension (10 min.)\n",
    "* Conversational question answering (5 min.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Relation extraction via reading comprehension\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/zeroshot-relation-extraction-via-reading-comprehension-conll-2017.pdf\">\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/fa025e5d117929361bcf798437957762eb5bb6d4/4-Figure2-1.png\" width=\"100%\">\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Levy et al., 2017](https://www.aclweb.org/anthology/K17-1034.pdf); [slides](https://levyomer.files.wordpress.com/2017/08/zeroshot-relation-extraction-via-reading-comprehension-conll-2017.pptx))\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flavours of Question answering (QA)\n",
    "\n",
    "* Factoid QA\n",
    "    * Information retrieval (IR) QA (by **machine reading comprehension** over text)\n",
    "    * Knowledge-base (KB) QA (by **semantic parsing** to logical form/SQL/SPARQL)\n",
    "* Non-factoid QA\n",
    "    * Math problems\n",
    "    * \"How\" questions\n",
    "    * \"Why\" questions\n",
    "    * ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### QA datasets\n",
    "\n",
    "* SQuAD ([Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf), [Rajpurkar & Jia et al., 2018](https://www.aclweb.org/anthology/P18-2124.pdf))\n",
    "* QuAC ([Choi et al., 2018](https://www.aclweb.org/anthology/D18-1241.pdf))\n",
    "* CoQA ([Reddy et al., 2019](https://www.aclweb.org/anthology/Q19-1016.pdf))\n",
    "* Natural Questions ([Kwiatkowski et al., 2019](https://www.aclweb.org/anthology/Q19-1026.pdf))\n",
    "* TyDI-QA ([Clark et al., 2020](https://www.aclweb.org/anthology/2020.tacl-1.30.pdf))\n",
    "* ...\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Information retrieval (IR)-based QA\n",
    "\n",
    "General approach:\n",
    "1. Retrieve relevant **passage**(s)\n",
    "2. Machine reading comprehension: extract the **answer**, which can be\n",
    "    * A text span from the passage\n",
    "    * Yes/no\n",
    "    * `NULL` (unanswerable)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Machine reading comprehension (MRC)\n",
    "\n",
    "* Input: (Passage, Question)\n",
    "* Output: Answer span\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://rajpurkar.github.io/mlx/qa-and-squad/example-squad.png\" width=\"50%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf))\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MRC demo\n",
    "\n",
    "### https://demo.allennlp.org/reading-comprehension/MjMzNTgxOA==\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MRC modeling\n",
    "\n",
    "How to model span selection?\n",
    "\n",
    "* As sequence labeling\n",
    "\n",
    "What may be the possible tags for each token? (poll)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MRC evaluation\n",
    "\n",
    "Test questions have $k$ gold answers by different human annotators ($k=3$ for SQuAD and TyDI-QA, $k=5$ for NQ)\n",
    "\n",
    "Metrics for binary (yes/no) QA:\n",
    "* **Accuracy**\n",
    "* **F1**\n",
    "\n",
    "Metrics for span selection:\n",
    "* **Exact match** (EM): text is exactly any of the $k$\n",
    "* Word **F1** (see [sequence labeling slides](sequence_labeling_slides.ipynb)) averaged over the $k$ gold answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SQuAD\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture10-QA.pdf\"><img src=\"qa_figures/squad.png\"></a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Rajpurkar et al., 2016](https://www.aclweb.org/anthology/D16-1264.pdf))\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MRC with BERT\n",
    "\n",
    "<center>\n",
    "    <img src=\"http://jalammar.github.io/images/bert-tasks.png\" width=60%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from <a href=\"https://www.aclweb.org/anthology/N19-1423.pdf\">Devlin et al., 2019</a>)\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversational QA\n",
    "\n",
    "### https://abbanmustafa.github.io/slides-deck-1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Knowledge-based (KB) question answering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Background Material\n",
    "\n",
    "* Jurafky, Dan and Martin, James H. (2016). Speech and Language Processing, Chapter 25 (Question Answering): https://web.stanford.edu/~jurafsky/slp3/25.pdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further Reading\n",
    "\n",
    "* Levy, O., Seo, M., Choi, E., & Zettlemoyer, L. (2017). Zero-Shot Relation Extraction via Reading Comprehension. Proceedings of CoNLL.  https://www.aclweb.org/anthology/K17-1034.pdf"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}